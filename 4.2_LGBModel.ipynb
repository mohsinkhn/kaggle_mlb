{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df7c857-e49d-414b-bba1-f64a8df5ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train LGB models.\"\"\"\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "from mllib.transformers import (\n",
    "    DateLagN,\n",
    "    ExpandingCount,\n",
    "    ExpandingMean,\n",
    "    ExpandingSum,\n",
    "    FunctionTransfomer,\n",
    "    LagN,\n",
    ")\n",
    "from src.constants import (\n",
    "    TARGETS,\n",
    "    awards_artifact,\n",
    "    event_artifact,\n",
    "    player_twitter_artifact,\n",
    "    rosters_artifact,\n",
    "    scores1_mean_artifact,\n",
    "    scores2_mean_artifact,\n",
    "    scores3_mean_artifact,\n",
    "    scores4_mean_artifact,\n",
    "    scores5_mean_artifact,\n",
    "    targets_artifact,\n",
    "    transactions_artifact,\n",
    ")\n",
    "from src.feature_gen1 import get_feature_pipeline1\n",
    "from src.pipelines.artifacts import DataLoader, MapToCol, ParseJsonField\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab572bd5-be83-4e3f-9095-3ed02580b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"data/train_updated.csv\"\n",
    "PLAYERS_FILE = \"data/players.csv\"\n",
    "VAL_START_DATE = 20210601\n",
    "DEVICE = \"gpu\"\n",
    "device = DEVICE\n",
    "artifacts_path = \"data/artifacts/v02\"\n",
    "SAVE_FEATURES = False\n",
    "LOAD_FEATURES = True\n",
    "TRAIN_SEASON_ONLY = True\n",
    "SEED1 = 786\n",
    "SEED2 = 20201102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68a520c-ee69-40bb-a1ab-f73aad8ec0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515799, 6) (20179, 6)\n"
     ]
    }
   ],
   "source": [
    "# raw_data = pd.read_csv(TRAIN_FILE)\n",
    "# tr = raw_data.loc[raw_data.date < VAL_START_DATE]\n",
    "# val = raw_data.loc[raw_data.date >= VAL_START_DATE]\n",
    "# print(raw_data.shape, val.shape)\n",
    "\n",
    "# roster_2021 = pd.read_csv(PLAYERS_FILE)\n",
    "# roster_2021 = roster_2021.loc[roster_2021.playerForTestSetAndFuturePreds == True]\n",
    "# target_enc = ParseJsonField(\n",
    "#     date_field=\"date\", data_field=\"nextDayPlayerEngagement\", use_cols=TARGETS+['playerId']\n",
    "# )\n",
    "# tr_index = target_enc.transform(tr).reset_index(drop=False)\n",
    "# tr_index = tr_index.loc[tr_index.playerId.isin(roster_2021.playerId.astype(str))]\n",
    "# del tr\n",
    "\n",
    "# vl_index = target_enc.transform(val).reset_index(drop=False)\n",
    "# vl_index = vl_index.loc[vl_index.playerId.isin(roster_2021.playerId.astype(str))]\n",
    "# del raw_data, val\n",
    "# # tr_index.to_csv(\"data/tr_index_smallv01.csv\", index=False)\n",
    "# # vl_index.to_csv(\"data/vl_index_smallv01.csv\", index=False)\n",
    "\n",
    "tr_index = pd.read_csv(\"data/tr_index_smallv02.csv\")\n",
    "vl_index = pd.read_csv(\"data/vl_index_smallv02.csv\")\n",
    "print(tr_index.shape, vl_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d8ad07-5d6c-4f77-91c4-f7e46de686e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline_tr1, feature_pipeline_te1 = get_feature_pipeline1(artifacts_path, 'gpu', [7, 30, 150, 1500], [10, 30, 150], [30, 150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b921182-1772-4ae9-a456-8592c41fd32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515799, 639) (20179, 639)\n",
      "(1038625, 639) (20179, 639) (1038625, 4) (20179, 4)\n"
     ]
    }
   ],
   "source": [
    "if not LOAD_FEATURES:\n",
    "    X_tr = feature_pipeline_tr1.transform(tr_index)\n",
    "    X_vl = feature_pipeline_te1.transform(vl_index)\n",
    "else:\n",
    "    X_tr = np.load(\"data/X_tr_v202_f1.npy\")\n",
    "    X_vl = np.load(\"data/X_vl_v202_f1.npy\")\n",
    "\n",
    "y_tr = tr_index[TARGETS].values\n",
    "y_vl = vl_index[TARGETS].values\n",
    "print(X_tr.shape, X_vl.shape)\n",
    "\n",
    "if SAVE_FEATURES:\n",
    "    np.save(\"data/X_tr_v202_f1.npy\", X_tr)\n",
    "    np.save(\"data/X_vl_v202_f1.npy\", X_vl)\n",
    "\n",
    "if TRAIN_SEASON_ONLY:\n",
    "    cond = X_tr[:, -1] > 0\n",
    "    X_tr = X_tr[cond]\n",
    "    y_tr = y_tr[cond]\n",
    "\n",
    "    cond = X_vl[:, -1] > 0\n",
    "    X_vl = X_vl[cond]\n",
    "    y_vl = y_vl[cond]\n",
    "    print(X_tr.shape, X_vl.shape, y_tr.shape, y_vl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17bedc18-1e64-4883-83a2-8c28e903fac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/envs/py38/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.98144\n",
      "[100]\tvalid_0's l1: 0.934452\n",
      "[150]\tvalid_0's l1: 0.914542\n",
      "[200]\tvalid_0's l1: 0.906327\n",
      "[250]\tvalid_0's l1: 0.901175\n",
      "[300]\tvalid_0's l1: 0.898819\n",
      "[350]\tvalid_0's l1: 0.897438\n",
      "[400]\tvalid_0's l1: 0.896347\n",
      "[450]\tvalid_0's l1: 0.895816\n",
      "[500]\tvalid_0's l1: 0.895316\n",
      "[550]\tvalid_0's l1: 0.894586\n",
      "[600]\tvalid_0's l1: 0.894079\n",
      "[650]\tvalid_0's l1: 0.893728\n",
      "[700]\tvalid_0's l1: 0.893256\n",
      "[750]\tvalid_0's l1: 0.892866\n",
      "[800]\tvalid_0's l1: 0.892351\n",
      "[850]\tvalid_0's l1: 0.892137\n",
      "[900]\tvalid_0's l1: 0.891846\n",
      "[950]\tvalid_0's l1: 0.891024\n",
      "[1000]\tvalid_0's l1: 0.890554\n",
      "[1050]\tvalid_0's l1: 0.889689\n",
      "[1100]\tvalid_0's l1: 0.889225\n",
      "[1150]\tvalid_0's l1: 0.888799\n",
      "[1200]\tvalid_0's l1: 0.888485\n",
      "[1250]\tvalid_0's l1: 0.888232\n",
      "[1300]\tvalid_0's l1: 0.88801\n",
      "[1350]\tvalid_0's l1: 0.887803\n",
      "[1400]\tvalid_0's l1: 0.887651\n",
      "[1450]\tvalid_0's l1: 0.887503\n",
      "[1500]\tvalid_0's l1: 0.887223\n",
      "[1550]\tvalid_0's l1: 0.886833\n",
      "[1600]\tvalid_0's l1: 0.886713\n",
      "[1650]\tvalid_0's l1: 0.886392\n",
      "[1700]\tvalid_0's l1: 0.886322\n",
      "[1750]\tvalid_0's l1: 0.886365\n",
      "[1800]\tvalid_0's l1: 0.886305\n",
      "[1850]\tvalid_0's l1: 0.886341\n",
      "[1900]\tvalid_0's l1: 0.886268\n",
      "[1950]\tvalid_0's l1: 0.886167\n",
      "[2000]\tvalid_0's l1: 0.886107\n",
      "[2050]\tvalid_0's l1: 0.885921\n",
      "[2100]\tvalid_0's l1: 0.885695\n",
      "[2150]\tvalid_0's l1: 0.885467\n",
      "[2200]\tvalid_0's l1: 0.885431\n",
      "[2250]\tvalid_0's l1: 0.885472\n",
      "[2300]\tvalid_0's l1: 0.885425\n",
      "[2350]\tvalid_0's l1: 0.885328\n",
      "[2400]\tvalid_0's l1: 0.885243\n",
      "[2450]\tvalid_0's l1: 0.88517\n",
      "[2500]\tvalid_0's l1: 0.885137\n",
      "[2550]\tvalid_0's l1: 0.885091\n",
      "[2600]\tvalid_0's l1: 0.885024\n",
      "[2650]\tvalid_0's l1: 0.884995\n",
      "[2700]\tvalid_0's l1: 0.884754\n",
      "[2750]\tvalid_0's l1: 0.884814\n",
      "[2800]\tvalid_0's l1: 0.884781\n",
      "[2850]\tvalid_0's l1: 0.884857\n",
      "[2900]\tvalid_0's l1: 0.884929\n",
      "[2950]\tvalid_0's l1: 0.884805\n",
      "[3000]\tvalid_0's l1: 0.884799\n",
      "Early stopping, best iteration is:\n",
      "[2822]\tvalid_0's l1: 0.884726\n",
      "0.8847260403880974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/envs/py38/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 1.24908\n",
      "[100]\tvalid_0's l1: 1.20185\n",
      "[150]\tvalid_0's l1: 1.21088\n",
      "[200]\tvalid_0's l1: 1.2154\n",
      "[250]\tvalid_0's l1: 1.22261\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's l1: 1.20091\n",
      "1.2009122612932897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/envs/py38/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.709156\n",
      "[100]\tvalid_0's l1: 0.698221\n",
      "[150]\tvalid_0's l1: 0.691918\n",
      "[200]\tvalid_0's l1: 0.688072\n",
      "[250]\tvalid_0's l1: 0.685668\n",
      "[300]\tvalid_0's l1: 0.684178\n",
      "[350]\tvalid_0's l1: 0.682848\n",
      "[400]\tvalid_0's l1: 0.681783\n",
      "[450]\tvalid_0's l1: 0.681374\n",
      "[500]\tvalid_0's l1: 0.68084\n",
      "[550]\tvalid_0's l1: 0.679515\n",
      "[600]\tvalid_0's l1: 0.678711\n",
      "[650]\tvalid_0's l1: 0.678069\n",
      "[700]\tvalid_0's l1: 0.677599\n",
      "[750]\tvalid_0's l1: 0.677379\n",
      "[800]\tvalid_0's l1: 0.676913\n",
      "[850]\tvalid_0's l1: 0.676881\n",
      "[900]\tvalid_0's l1: 0.676816\n",
      "[950]\tvalid_0's l1: 0.676736\n",
      "[1000]\tvalid_0's l1: 0.676579\n",
      "[1050]\tvalid_0's l1: 0.676275\n",
      "[1100]\tvalid_0's l1: 0.675957\n",
      "[1150]\tvalid_0's l1: 0.675404\n",
      "[1200]\tvalid_0's l1: 0.675158\n",
      "[1250]\tvalid_0's l1: 0.674715\n",
      "[1300]\tvalid_0's l1: 0.674462\n",
      "[1350]\tvalid_0's l1: 0.674453\n",
      "[1400]\tvalid_0's l1: 0.674249\n",
      "[1450]\tvalid_0's l1: 0.674115\n",
      "[1500]\tvalid_0's l1: 0.673998\n",
      "[1550]\tvalid_0's l1: 0.674004\n",
      "[1600]\tvalid_0's l1: 0.673842\n",
      "[1650]\tvalid_0's l1: 0.67375\n",
      "[1700]\tvalid_0's l1: 0.67342\n",
      "[1750]\tvalid_0's l1: 0.673375\n",
      "[1800]\tvalid_0's l1: 0.673136\n",
      "[1850]\tvalid_0's l1: 0.673049\n",
      "[1900]\tvalid_0's l1: 0.672972\n",
      "[1950]\tvalid_0's l1: 0.672653\n",
      "[2000]\tvalid_0's l1: 0.672427\n",
      "[2050]\tvalid_0's l1: 0.67236\n",
      "[2100]\tvalid_0's l1: 0.672248\n",
      "[2150]\tvalid_0's l1: 0.672224\n",
      "[2200]\tvalid_0's l1: 0.67214\n",
      "[2250]\tvalid_0's l1: 0.672011\n",
      "[2300]\tvalid_0's l1: 0.671758\n",
      "[2350]\tvalid_0's l1: 0.671688\n",
      "[2400]\tvalid_0's l1: 0.671664\n",
      "[2450]\tvalid_0's l1: 0.671562\n",
      "[2500]\tvalid_0's l1: 0.671628\n",
      "[2550]\tvalid_0's l1: 0.671683\n",
      "[2600]\tvalid_0's l1: 0.671612\n",
      "[2650]\tvalid_0's l1: 0.671607\n",
      "Early stopping, best iteration is:\n",
      "[2465]\tvalid_0's l1: 0.671505\n",
      "0.6715044988707483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/envs/py38/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.608192\n",
      "[100]\tvalid_0's l1: 0.638607\n",
      "[150]\tvalid_0's l1: 0.675789\n",
      "[200]\tvalid_0's l1: 0.696082\n",
      "[250]\tvalid_0's l1: 0.710729\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l1: 0.605743\n",
      "0.6057425671425748\n",
      "Overall score for params 1 -> f0.8407\n"
     ]
    }
   ],
   "source": [
    "tr1 = lgb.Dataset(X_tr, y_tr[:, 0])\n",
    "tr2 = lgb.Dataset(X_tr, y_tr[:, 1])\n",
    "tr3 = lgb.Dataset(X_tr, y_tr[:, 2])\n",
    "tr4 = lgb.Dataset(X_tr, y_tr[:, 3])\n",
    "\n",
    "vl1 = lgb.Dataset(X_vl, y_vl[:, 0], reference=tr1)\n",
    "vl2 = lgb.Dataset(X_vl, y_vl[:, 1], reference=tr2)\n",
    "vl3 = lgb.Dataset(X_vl, y_vl[:, 2], reference=tr3)\n",
    "vl4 = lgb.Dataset(X_vl, y_vl[:, 3], reference=tr4)\n",
    "\n",
    "params1 = {\n",
    "    \"n_estimators\": 5000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 255,\n",
    "    \"max_depth\": -1,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"subsample\": 0.95,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    \"extra_trees\": False,\n",
    "    \"max_bin\": 127,\n",
    "    # 'device': 'gpu',\n",
    "    # 'gpu_use_dp': False,\n",
    "    # 'gpu_device_id': 0,\n",
    "    \"boost_from_average\": True,\n",
    "    \"reg_sqrt\": True,\n",
    "    \"objective\": \"mae\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"verbose\": -1,\n",
    "    \"seed\": SEED1,\n",
    "    \"min_data_per_group\": 10,\n",
    "    \"cat_l2\": 10,\n",
    "    \"cat_smooth\": 10,\n",
    "    \"num_threads\": 16,\n",
    "}\n",
    "\n",
    "bst1 = lgb.train(params1, tr1, valid_sets=[vl1], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred21 = bst1.predict(X_vl)\n",
    "print(mae(y_vl[:, 0], pred21))\n",
    "\n",
    "bst2 = lgb.train(params1, tr2, valid_sets=[vl2], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred22 = bst2.predict(X_vl)\n",
    "print(mae(y_vl[:, 1], pred22))\n",
    "\n",
    "bst3 = lgb.train(params1, tr3, valid_sets=[vl3], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred23 = bst3.predict(X_vl)\n",
    "print(mae(y_vl[:, 2], pred23))\n",
    "\n",
    "bst4 = lgb.train(params1, tr4, valid_sets=[vl4], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred24 = bst4.predict(X_vl)\n",
    "print(mae(y_vl[:, 3], pred24))\n",
    "\n",
    "preds_2 = np.vstack((pred21, pred22, pred23, pred24)).T\n",
    "print(f\"Overall score for params 1 -> f{mae(y_vl, preds_2):6.4f}\")\n",
    "bst1.save_model(f\"artifacts/bst1_train_v402_1.pkl\")\n",
    "bst2.save_model(f\"artifacts/bst2_train_v402_1.pkl\")\n",
    "bst3.save_model(f\"artifacts/bst3_train_v402_1.pkl\")\n",
    "bst4.save_model(f\"artifacts/bst4_train_v402_1.pkl\")\n",
    "\n",
    "np.save(f\"data/lgb_t1_logv402_skip10_1.npy\", pred21)\n",
    "np.save(f\"data/lgb_t2_logv402_skip10_1.npy\", pred22)\n",
    "np.save(f\"data/lgb_t3_logv402_skip10_1.npy\", pred23)\n",
    "np.save(f\"data/lgb_t4_logv402_skip10_1.npy\", pred24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9161a52b-631d-478f-948c-98c7a6f90c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_tr, X_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a30ae5b9-defd-495f-ad50-a390f74a448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline_tr2, feature_pipeline_te2 = get_feature_pipeline1(artifacts_path, 'gpu', [7, 30, 90, 500], [7, 21, 90], [21, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd09d88-66c4-439e-9a04-910418a43c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515799, 639) (20179, 639)\n",
      "(1038625, 639) (20179, 639) (1038625, 4) (20179, 4)\n"
     ]
    }
   ],
   "source": [
    "if not LOAD_FEATURES:\n",
    "    X_tr = feature_pipeline_tr2.transform(tr_index)\n",
    "    X_vl = feature_pipeline_te2.transform(vl_index)\n",
    "else:\n",
    "    X_tr = np.load(\"data/X_tr_v202_f2.npy\")\n",
    "    X_vl = np.load(\"data/X_vl_v202_f2.npy\")\n",
    "\n",
    "y_tr = tr_index[TARGETS].values\n",
    "y_vl = vl_index[TARGETS].values\n",
    "print(X_tr.shape, X_vl.shape)\n",
    "\n",
    "if SAVE_FEATURES:\n",
    "    np.save(\"data/X_tr_v202_f2.npy\", X_tr)\n",
    "    np.save(\"data/X_vl_v202_f2.npy\", X_vl)\n",
    "\n",
    "if TRAIN_SEASON_ONLY:\n",
    "    cond = X_tr[:, -1] > 0\n",
    "    X_tr = X_tr[cond]\n",
    "    y_tr = y_tr[cond]\n",
    "\n",
    "    cond = X_vl[:, -1] > 0\n",
    "    X_vl = X_vl[cond]\n",
    "    y_vl = y_vl[cond]\n",
    "    print(X_tr.shape, X_vl.shape, y_tr.shape, y_vl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037b2a0a-f90e-42af-b7f7-2a2cd3003118",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_tr.astype(np.float32)\n",
    "X_vl = X_vl.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6c7c73-1a2b-4f01-8633-d65575dc2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.983373\n",
      "[100]\tvalid_0's l1: 0.934525\n",
      "[150]\tvalid_0's l1: 0.915653\n",
      "[200]\tvalid_0's l1: 0.908637\n",
      "[250]\tvalid_0's l1: 0.903885\n",
      "[300]\tvalid_0's l1: 0.901091\n",
      "[350]\tvalid_0's l1: 0.899427\n",
      "[400]\tvalid_0's l1: 0.898176\n",
      "[450]\tvalid_0's l1: 0.897821\n",
      "[500]\tvalid_0's l1: 0.89714\n",
      "[550]\tvalid_0's l1: 0.896778\n",
      "[600]\tvalid_0's l1: 0.89623\n",
      "[650]\tvalid_0's l1: 0.895597\n",
      "[700]\tvalid_0's l1: 0.895021\n",
      "[750]\tvalid_0's l1: 0.893831\n",
      "[800]\tvalid_0's l1: 0.893006\n",
      "[850]\tvalid_0's l1: 0.892819\n",
      "[900]\tvalid_0's l1: 0.89213\n",
      "[950]\tvalid_0's l1: 0.891513\n",
      "[1000]\tvalid_0's l1: 0.891239\n",
      "[1050]\tvalid_0's l1: 0.89072\n",
      "[1100]\tvalid_0's l1: 0.890075\n",
      "[1150]\tvalid_0's l1: 0.889427\n",
      "[1200]\tvalid_0's l1: 0.889048\n",
      "[1250]\tvalid_0's l1: 0.888425\n",
      "[1300]\tvalid_0's l1: 0.888265\n",
      "[1350]\tvalid_0's l1: 0.887853\n",
      "[1400]\tvalid_0's l1: 0.887697\n",
      "[1450]\tvalid_0's l1: 0.887461\n",
      "[1500]\tvalid_0's l1: 0.887388\n",
      "[1550]\tvalid_0's l1: 0.887214\n",
      "[1600]\tvalid_0's l1: 0.887251\n",
      "[1650]\tvalid_0's l1: 0.887182\n",
      "[1700]\tvalid_0's l1: 0.886909\n",
      "[1750]\tvalid_0's l1: 0.88658\n",
      "[1800]\tvalid_0's l1: 0.886342\n",
      "[1850]\tvalid_0's l1: 0.88612\n",
      "[1900]\tvalid_0's l1: 0.88592\n",
      "[1950]\tvalid_0's l1: 0.8859\n",
      "[2000]\tvalid_0's l1: 0.885914\n",
      "[2050]\tvalid_0's l1: 0.885793\n",
      "[2100]\tvalid_0's l1: 0.885765\n",
      "[2150]\tvalid_0's l1: 0.885652\n",
      "[2200]\tvalid_0's l1: 0.885599\n",
      "[2250]\tvalid_0's l1: 0.885598\n",
      "[2300]\tvalid_0's l1: 0.88563\n",
      "[2350]\tvalid_0's l1: 0.885418\n",
      "[2400]\tvalid_0's l1: 0.885491\n",
      "[2450]\tvalid_0's l1: 0.885371\n",
      "[2500]\tvalid_0's l1: 0.885312\n",
      "[2550]\tvalid_0's l1: 0.884994\n",
      "[2600]\tvalid_0's l1: 0.885011\n",
      "[2650]\tvalid_0's l1: 0.884966\n",
      "[2700]\tvalid_0's l1: 0.884828\n",
      "[2750]\tvalid_0's l1: 0.884771\n",
      "[2800]\tvalid_0's l1: 0.884599\n",
      "[2850]\tvalid_0's l1: 0.884759\n",
      "[2900]\tvalid_0's l1: 0.884531\n",
      "[2950]\tvalid_0's l1: 0.884512\n",
      "[3000]\tvalid_0's l1: 0.884408\n",
      "[3050]\tvalid_0's l1: 0.884382\n",
      "[3100]\tvalid_0's l1: 0.884267\n",
      "[3150]\tvalid_0's l1: 0.884315\n",
      "[3200]\tvalid_0's l1: 0.884345\n",
      "[3250]\tvalid_0's l1: 0.884427\n",
      "[3300]\tvalid_0's l1: 0.88446\n",
      "[3350]\tvalid_0's l1: 0.884486\n",
      "Early stopping, best iteration is:\n",
      "[3178]\tvalid_0's l1: 0.884201\n",
      "0.884201360018904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/envs/py38/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 1.24508\n",
      "[100]\tvalid_0's l1: 1.19117\n",
      "[150]\tvalid_0's l1: 1.19423\n",
      "[200]\tvalid_0's l1: 1.2044\n",
      "[250]\tvalid_0's l1: 1.20672\n",
      "[300]\tvalid_0's l1: 1.20579\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's l1: 1.18944\n",
      "1.1894360589400466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/envs/py38/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.709659\n",
      "[100]\tvalid_0's l1: 0.698058\n",
      "[150]\tvalid_0's l1: 0.691565\n",
      "[200]\tvalid_0's l1: 0.686994\n",
      "[250]\tvalid_0's l1: 0.685063\n",
      "[300]\tvalid_0's l1: 0.683261\n",
      "[350]\tvalid_0's l1: 0.682382\n",
      "[400]\tvalid_0's l1: 0.68101\n",
      "[450]\tvalid_0's l1: 0.680063\n",
      "[500]\tvalid_0's l1: 0.679181\n",
      "[550]\tvalid_0's l1: 0.678809\n",
      "[600]\tvalid_0's l1: 0.678298\n",
      "[650]\tvalid_0's l1: 0.677742\n",
      "[700]\tvalid_0's l1: 0.677177\n",
      "[750]\tvalid_0's l1: 0.676375\n",
      "[800]\tvalid_0's l1: 0.675099\n",
      "[850]\tvalid_0's l1: 0.674524\n",
      "[900]\tvalid_0's l1: 0.673971\n",
      "[950]\tvalid_0's l1: 0.673561\n",
      "[1000]\tvalid_0's l1: 0.673071\n",
      "[1050]\tvalid_0's l1: 0.672514\n",
      "[1100]\tvalid_0's l1: 0.672381\n",
      "[1150]\tvalid_0's l1: 0.671952\n",
      "[1200]\tvalid_0's l1: 0.671662\n",
      "[1250]\tvalid_0's l1: 0.670964\n",
      "[1300]\tvalid_0's l1: 0.670783\n",
      "[1350]\tvalid_0's l1: 0.6706\n",
      "[1400]\tvalid_0's l1: 0.670222\n",
      "[1450]\tvalid_0's l1: 0.669862\n",
      "[1500]\tvalid_0's l1: 0.669796\n",
      "[1550]\tvalid_0's l1: 0.66973\n",
      "[1600]\tvalid_0's l1: 0.669548\n",
      "[1650]\tvalid_0's l1: 0.669307\n",
      "[1700]\tvalid_0's l1: 0.669217\n",
      "[1750]\tvalid_0's l1: 0.668973\n",
      "[1800]\tvalid_0's l1: 0.668938\n",
      "[1850]\tvalid_0's l1: 0.668597\n",
      "[1900]\tvalid_0's l1: 0.668082\n",
      "[1950]\tvalid_0's l1: 0.667586\n",
      "[2000]\tvalid_0's l1: 0.667467\n",
      "[2050]\tvalid_0's l1: 0.667114\n",
      "[2100]\tvalid_0's l1: 0.667018\n",
      "[2150]\tvalid_0's l1: 0.666538\n",
      "[2200]\tvalid_0's l1: 0.666286\n",
      "[2250]\tvalid_0's l1: 0.666102\n",
      "[2300]\tvalid_0's l1: 0.6658\n",
      "[2350]\tvalid_0's l1: 0.665581\n",
      "[2400]\tvalid_0's l1: 0.665457\n",
      "[2450]\tvalid_0's l1: 0.665363\n",
      "[2500]\tvalid_0's l1: 0.665361\n",
      "[2550]\tvalid_0's l1: 0.665013\n",
      "[2600]\tvalid_0's l1: 0.665179\n",
      "[2650]\tvalid_0's l1: 0.665072\n",
      "[2700]\tvalid_0's l1: 0.664727\n",
      "[2750]\tvalid_0's l1: 0.664354\n",
      "[2800]\tvalid_0's l1: 0.664096\n",
      "[2850]\tvalid_0's l1: 0.663844\n",
      "[2900]\tvalid_0's l1: 0.663904\n",
      "[2950]\tvalid_0's l1: 0.663634\n",
      "[3000]\tvalid_0's l1: 0.663497\n",
      "[3050]\tvalid_0's l1: 0.663446\n",
      "[3100]\tvalid_0's l1: 0.663301\n",
      "[3150]\tvalid_0's l1: 0.663485\n",
      "[3200]\tvalid_0's l1: 0.663494\n",
      "[3250]\tvalid_0's l1: 0.6635\n",
      "[3300]\tvalid_0's l1: 0.663338\n",
      "[3350]\tvalid_0's l1: 0.663256\n",
      "[3400]\tvalid_0's l1: 0.663221\n",
      "[3450]\tvalid_0's l1: 0.663259\n",
      "[3500]\tvalid_0's l1: 0.663229\n",
      "[3550]\tvalid_0's l1: 0.663071\n",
      "[3600]\tvalid_0's l1: 0.66289\n",
      "[3650]\tvalid_0's l1: 0.662779\n",
      "[3700]\tvalid_0's l1: 0.662885\n",
      "[3750]\tvalid_0's l1: 0.66235\n",
      "[3800]\tvalid_0's l1: 0.662571\n",
      "[3850]\tvalid_0's l1: 0.662666\n",
      "[3900]\tvalid_0's l1: 0.662659\n",
      "Early stopping, best iteration is:\n",
      "[3739]\tvalid_0's l1: 0.662324\n",
      "0.6623242228348174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/envs/py38/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.611744\n",
      "[100]\tvalid_0's l1: 0.635798\n",
      "[150]\tvalid_0's l1: 0.671099\n",
      "[200]\tvalid_0's l1: 0.691093\n",
      "[250]\tvalid_0's l1: 0.703045\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l1: 0.608073\n",
      "0.608073393505657\n",
      "Overall score for params 2 -> f0.8360\n"
     ]
    }
   ],
   "source": [
    "tr1 = lgb.Dataset(X_tr, y_tr[:, 0])\n",
    "tr2 = lgb.Dataset(X_tr, y_tr[:, 1])\n",
    "tr3 = lgb.Dataset(X_tr, y_tr[:, 2])\n",
    "tr4 = lgb.Dataset(X_tr, y_tr[:, 3])\n",
    "\n",
    "vl1 = lgb.Dataset(X_vl, y_vl[:, 0], reference=tr1)\n",
    "vl2 = lgb.Dataset(X_vl, y_vl[:, 1], reference=tr2)\n",
    "vl3 = lgb.Dataset(X_vl, y_vl[:, 2], reference=tr3)\n",
    "vl4 = lgb.Dataset(X_vl, y_vl[:, 3], reference=tr4)\n",
    "\n",
    "params1 = {\n",
    "    \"n_estimators\": 5000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 255,\n",
    "    \"max_depth\": -1,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"colsample_bytree\": 0.4,\n",
    "    \"subsample\": 0.95,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    \"extra_trees\": False,\n",
    "    \"max_bin\": 127,\n",
    "#     'device': 'gpu',\n",
    "#     'gpu_use_dp': False,\n",
    "#     'gpu_device_id': 0,\n",
    "    \"boost_from_average\": True,\n",
    "    \"reg_sqrt\": True,\n",
    "    \"objective\": \"mae\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"verbose\": -1,\n",
    "    \"seed\": SEED2,\n",
    "    \"min_data_per_group\": 10,\n",
    "    \"cat_l2\": 10,\n",
    "    \"cat_smooth\": 10,\n",
    "    \"num_threads\": 16,\n",
    "}\n",
    "\n",
    "bst1 = lgb.train(params1, tr1, valid_sets=[vl1], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred21 = bst1.predict(X_vl)\n",
    "print(mae(y_vl[:, 0], pred21))\n",
    "\n",
    "bst2 = lgb.train(params1, tr2, valid_sets=[vl2], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred22 = bst2.predict(X_vl)\n",
    "print(mae(y_vl[:, 1], pred22))\n",
    "\n",
    "bst3 = lgb.train(params1, tr3, valid_sets=[vl3], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred23 = bst3.predict(X_vl)\n",
    "print(mae(y_vl[:, 2], pred23))\n",
    "\n",
    "bst4 = lgb.train(params1, tr4, valid_sets=[vl4], early_stopping_rounds=200, verbose_eval=50)\n",
    "pred24 = bst4.predict(X_vl)\n",
    "print(mae(y_vl[:, 3], pred24))\n",
    "\n",
    "preds_2 = np.vstack((pred21, pred22, pred23, pred24)).T\n",
    "print(f\"Overall score for params 2 -> f{mae(y_vl, preds_2):6.4f}\")\n",
    "bst1.save_model(f\"artifacts/bst1_train_v402_2.pkl\")\n",
    "bst2.save_model(f\"artifacts/bst2_train_v402_2.pkl\")\n",
    "bst3.save_model(f\"artifacts/bst3_train_v402_2.pkl\")\n",
    "bst4.save_model(f\"artifacts/bst4_train_v402_2.pkl\")\n",
    "\n",
    "np.save(f\"data/lgb_t1_logv402_skip10_2.npy\", pred21)\n",
    "np.save(f\"data/lgb_t2_logv402_skip10_2.npy\", pred22)\n",
    "np.save(f\"data/lgb_t3_logv402_skip10_2.npy\", pred23)\n",
    "np.save(f\"data/lgb_t4_logv402_skip10_2.npy\", pred24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a7f3d-61af-482a-856d-24bbcfb98f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
