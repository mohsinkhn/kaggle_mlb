{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb785e4a-eacf-450e-87aa-3aae7b254703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "\n",
    "from mllib.transformers import *\n",
    "from src.pipelines.artifacts import ParsePlayerData\n",
    "from src.utils.utils import print_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82229a74-1b1c-4f31-b52c-e6184285c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate index\n",
    "TRAIN_FILE = \"data/train.csv\"\n",
    "PLAYERS_FILE = \"data/players.csv\"\n",
    "VAL_START_DATE = 20210415\n",
    "TARGETS = [\"target1\", \"target2\", \"target3\", \"target4\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b727866-3ca3-48c9-9e01-f1c50722f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1216, 12) (16, 12)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(TRAIN_FILE)\n",
    "tr = raw_data.loc[raw_data.date < VAL_START_DATE]\n",
    "val = raw_data.loc[raw_data.date >= VAL_START_DATE]\n",
    "print(raw_data.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1a0926-c036-4df5-bbde-664b774436df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.artifacts import ParseJsonField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5241e88-e9a2-4c66-bbd8-d971c2f7b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = ParseJsonField('date', 'rosters', use_cols=['status', 'statusCode'])\n",
    "# roster_df = parser.transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a059cf0-c4ff-403f-9097-623c12919579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:17<00:00, 67.85it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 64.58it/s]\n"
     ]
    }
   ],
   "source": [
    "roster_2021 = pd.read_csv(PLAYERS_FILE)\n",
    "roster_2021 = roster_2021.loc[roster_2021.playerForTestSetAndFuturePreds == True]\n",
    "target_enc = ParsePlayerData(\"nextDayPlayerEngagement\", TARGETS)\n",
    "tr_index = target_enc.fit_transform(tr).reset_index(drop=False)\n",
    "tr_index = tr_index.loc[tr_index.playerId.isin(roster_2021.playerId.astype(str))]\n",
    "# tr_index['debutdate'] = tr_index.map()\n",
    "vl_index = target_enc.fit_transform(val).reset_index(drop=False)\n",
    "vl_index = vl_index.loc[vl_index.playerId.isin(roster_2021.playerId.astype(str))]\n",
    "tr_index.to_csv(\"data/tr_index_small.csv\", index=False)\n",
    "vl_index.to_csv(\"data/vl_index_small.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391b7a8b-ba45-48e6-9bd4-641091011360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1424400, 6), (18992, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_index = pd.read_csv(\"data/tr_index_small.csv\")\n",
    "vl_index = pd.read_csv(\"data/vl_index_small.csv\")\n",
    "tr_index.shape, vl_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f161bfb-2be4-420b-ae5e-da77bbbce80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'gpu'\n",
    "artifacts_path = 'data/artifacts/tmp'\n",
    "feature_pipeline = make_union(\n",
    "    LagN('date', 'playerId', [0, 1, 2, 3], f'{artifacts_path}/train_plscores3.pkl', 'data/', N=1, skip=0, device=device),\n",
    "    LagN('date', 'playerId', [0, 1, 2, 3], f'{artifacts_path}/train_plscores3.pkl', 'data/', N=2, skip=0, device=device),\n",
    "    ExpandingSum('date', 'playerId', [0, 1, 2, 3], f'{artifacts_path}/train_plscores3.pkl', 'data/', N=30, skip=0, device=device),\n",
    "    ExpandingSum('date', 'playerId', [0, 1, 2, 3], f'{artifacts_path}/train_plscores3.pkl', 'data/', N=300, skip=0, device=device),\n",
    "    LagN('date', 'playerId', [0, 1, 2, 3], f'{artifacts_path}/train_plscores1.pkl', 'data/', N=1, skip=0, device=device),\n",
    "    LagN('date', 'playerId', [4], f'{artifacts_path}/train_plscores1.pkl', 'data/', N=1, skip=0, device=device),\n",
    "    LagN('date', 'playerId', [0, 1, 2, 3], f'{artifacts_path}/train_plscores1.pkl', 'data/', N=2, skip=0, device=device),\n",
    "    LagN('date', 'playerId', [4], f'{artifacts_path}/train_plscores1.pkl', 'data/', N=2, skip=0, device=device),\n",
    "    *[\n",
    "        LagN('date', 'playerId', list(range(i*4, (i+1)*4)), f'{artifacts_path}/train_plscores2.pkl', 'data/', N=j+1, skip=0, device=device)\n",
    "        for j in range(2) for i in range(6)\n",
    "     ],\n",
    "    *[\n",
    "        ExpandingMean('date', 'playerId', list(range(i*4, (i+1)*4)), f'{artifacts_path}/train_plscores2.pkl', 'data/', N=j, skip=0, device=device)\n",
    "        for j in [10, 30, 300] for i in range(6)\n",
    "     ],\n",
    "    *[\n",
    "        ExpandingSum('date', 'playerId', list(range(i*4, (i+1)*4)), f'{artifacts_path}/train_plscores2.pkl', 'data/', N=j, skip=0, device=device)\n",
    "        for j in [10, 30, 300] for i in range(6)\n",
    "     ],\n",
    "    *[\n",
    "        LagN('date', 'playerId', list(range(i*4, (i+1)*4)), f'{artifacts_path}/train_plscores4.pkl', 'data/', N=j+1, skip=0, device=device)\n",
    "        for j in range(2) for i in range(3)\n",
    "     ],\n",
    "    *[\n",
    "        ExpandingMean('date', 'playerId', list(range(i*4, (i+1)*4)), f'{artifacts_path}/train_plscores4.pkl', 'data/', N=j, skip=0, device=device)\n",
    "        for j in [10, 30, 300] for i in range(3)\n",
    "     ],\n",
    "    *[\n",
    "        ExpandingSum('date', 'playerId', list(range(i*4, (i+1)*4)), f'{artifacts_path}/train_plscores4.pkl', 'data/', N=j, skip=0, device=device)\n",
    "        for j in [10, 30, 300] for i in range(3)\n",
    "     ],\n",
    "    *[\n",
    "        LagN('date', 'playerId', [12, 13, 14], f'{artifacts_path}/train_plscores4.pkl', 'data/', N=j+1, skip=0, device=device)\n",
    "        for j in range(2)\n",
    "     ],\n",
    "    *[\n",
    "        ExpandingMean('date', 'playerId', [12, 13, 14], f'{artifacts_path}/train_plscores4.pkl', 'data/', N=j, skip=0, device=device)\n",
    "        for j in [10, 30, 300]\n",
    "     ],\n",
    "    *[\n",
    "        ExpandingSum('date', 'playerId', [12, 13, 14], f'{artifacts_path}/train_plscores4.pkl', 'data/', N=j, skip=0, device=device)\n",
    "        for j in [10, 30, 300]\n",
    "     ],\n",
    "    *[\n",
    "        LagN('date', 'playerId', list(range(i*4, (i+1)*4)), f'{artifacts_path}/train_plscores5.pkl', 'data/', N=1, skip=0, device=device)\n",
    "        for i in range(5)\n",
    "     ],\n",
    "    LagN('date', 'playerId', [20], f'{artifacts_path}/train_plscores5.pkl', 'data/', N=1, skip=0, device=device),\n",
    "    ExpandingMean('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=10, skip=3, device=device), \n",
    "    ExpandingMean('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=28, skip=3, device=device), \n",
    "    ExpandingMean('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=365, skip=3, device=device), \n",
    "    ExpandingMean('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=1500, skip=3, device=device), \n",
    "    ExpandingMax('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=28, skip=3, device=device), \n",
    "    ExpandingQ75('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=28, skip=3, device=device), \n",
    "    ExpandingQ25('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=28, skip=3, device=device), \n",
    "    ExpandingQ05('date', 'playerId', list(range(0, 4)), f'{artifacts_path}/train_targets.pkl', 'data/', N=28, skip=3, device=device),\n",
    "    LagN('date', 'playerId', [0], f'{artifacts_path}/train_awards.pkl', 'data/', fill_value=np.nan, N=1, skip=0, device=device),\n",
    "    ExpandingCount('date', 'playerId', [0], f'{artifacts_path}/train_awards.pkl', 'data/', fill_value=np.nan, N=365, skip=0, device=device),\n",
    "    LagN('date', 'playerId', [0], f'{artifacts_path}/train_transactions.pkl', 'data/', fill_value=np.nan, N=1, skip=0, device=device),\n",
    "    LagN('date', 'playerId', [0, 1], f'{artifacts_path}/train_rosters.pkl', 'data/', fill_value=np.nan, N=1, skip=0, device=device),\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3be9303-f677-4131-9ce8-f5a8624da7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "CPU times: user 4min 45s, sys: 9.91 s, total: 4min 55s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_tr1 = feature_pipeline.transform(tr_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1d650e9-bf48-447b-b59f-1628edc8c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "Applied time series transformer\n",
      "CPU times: user 15.1 s, sys: 725 ms, total: 15.8 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_vl1 = feature_pipeline.transform(vl_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26c08c83-6487-4fd8-8bc0-7b2f6c6b1548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424400, 396)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23eb35e4-6870-47ec-bc21-e8bc3c8138ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin_okcredit_in/anaconda3/envs/setienv/lib/python3.8/site-packages/lightgbm/engine.py:154: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/mohsin_okcredit_in/anaconda3/envs/setienv/lib/python3.8/site-packages/lightgbm/basic.py:1991: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/mohsin_okcredit_in/anaconda3/envs/setienv/lib/python3.8/site-packages/lightgbm/basic.py:1994: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [13, 14, 15, 16]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/home/mohsin_okcredit_in/anaconda3/envs/setienv/lib/python3.8/site-packages/lightgbm/basic.py:1722: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/mohsin_okcredit_in/anaconda3/envs/setienv/lib/python3.8/site-packages/lightgbm/basic.py:1456: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 1.16975\n",
      "[100]\tvalid_0's l1: 1.12823\n",
      "[150]\tvalid_0's l1: 1.11685\n",
      "[200]\tvalid_0's l1: 1.11377\n",
      "[250]\tvalid_0's l1: 1.11337\n",
      "[300]\tvalid_0's l1: 1.11277\n",
      "[350]\tvalid_0's l1: 1.11186\n",
      "[400]\tvalid_0's l1: 1.11161\n",
      "[450]\tvalid_0's l1: 1.11103\n",
      "[500]\tvalid_0's l1: 1.10969\n",
      "[550]\tvalid_0's l1: 1.10909\n",
      "[600]\tvalid_0's l1: 1.10883\n",
      "[650]\tvalid_0's l1: 1.1086\n",
      "[700]\tvalid_0's l1: 1.10856\n",
      "[750]\tvalid_0's l1: 1.1084\n",
      "[800]\tvalid_0's l1: 1.10836\n",
      "[850]\tvalid_0's l1: 1.10819\n",
      "[900]\tvalid_0's l1: 1.10815\n",
      "[950]\tvalid_0's l1: 1.10796\n",
      "[1000]\tvalid_0's l1: 1.10784\n",
      "[1050]\tvalid_0's l1: 1.10735\n",
      "[1100]\tvalid_0's l1: 1.10664\n",
      "[1150]\tvalid_0's l1: 1.10564\n",
      "[1200]\tvalid_0's l1: 1.10523\n",
      "[1250]\tvalid_0's l1: 1.10512\n",
      "[1300]\tvalid_0's l1: 1.1047\n",
      "[1350]\tvalid_0's l1: 1.10421\n",
      "[1400]\tvalid_0's l1: 1.10407\n",
      "[1450]\tvalid_0's l1: 1.10405\n",
      "[1500]\tvalid_0's l1: 1.10419\n",
      "Early stopping, best iteration is:\n",
      "[1333]\tvalid_0's l1: 1.10402\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "targets = ['target1', 'target2', 'target3', 'target4']\n",
    "y_tr = tr_index[targets].values\n",
    "y_vl = vl_index[targets].values\n",
    "# print(np.unique(X_tra[:, 235]))\n",
    "tr1 = lgb.Dataset(X_tr1, y_tr[:, 0], categorical_feature=[13, 14, 15, 16, ])\n",
    "tr2 = lgb.Dataset(X_tr1, y_tr[:, 1], categorical_feature=[13, 14, 15, 16, ])\n",
    "tr3 = lgb.Dataset(X_tr1, y_tr[:, 2], categorical_feature=[13, 14, 15, 16, ])\n",
    "tr4 = lgb.Dataset(X_tr1, y_tr[:, 3], categorical_feature=[13, 14, 15, 16, ])\n",
    "\n",
    "vl1 = lgb.Dataset(X_vl1, y_vl[:, 0], reference=tr1)\n",
    "vl2 = lgb.Dataset(X_vl1, y_vl[:, 1], reference=tr2)\n",
    "vl3 = lgb.Dataset(X_vl1, y_vl[:, 2], reference=tr3)\n",
    "vl4 = lgb.Dataset(X_vl1, y_vl[:, 3], reference=tr4)\n",
    "\n",
    "# params = {\n",
    "#     'n_estimators': 4000,\n",
    "#     'learning_rate': 0.08,\n",
    "#     'num_leaves': 31,\n",
    "#     'colsample_bytree': 0.3,\n",
    "#     'subsample': 0.5,\n",
    "#     'reg_alpha': 0.1,\n",
    "#     'reg_lambda': 0.1,\n",
    "#     'max_bin': 255,\n",
    "#     'objective': 'mae',\n",
    "#     'metric': 'mae'\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 4000,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 255,\n",
    "    'max_depth': -1,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'subsample': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'extra_trees': False,\n",
    "    'max_bin': 127,\n",
    "    #'device': 'gpu',\n",
    "    #'gpu_use_dp': False,\n",
    "    #'gpu_device_id': 0,\n",
    "    'boost_from_average': True,\n",
    "    'reg_sqrt': True,\n",
    "    'objective': 'mae',\n",
    "    'metric': 'mae',\n",
    "    'verbose': -1,\n",
    "    'seed': 123478659,\n",
    "    'min_data_per_group': 10,\n",
    "    'cat_l2': 1,\n",
    "    'cat_smooth': 10,\n",
    "    'num_threads': 16\n",
    "}\n",
    "bst1 = lgb.train(params, tr1, valid_sets=[vl1], early_stopping_rounds=200, verbose_eval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c026bad-418a-42ce-86c8-ac348308df07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 2.16356\n",
      "[100]\tvalid_0's l1: 2.11912\n",
      "[150]\tvalid_0's l1: 2.09684\n",
      "[200]\tvalid_0's l1: 2.08897\n",
      "[250]\tvalid_0's l1: 2.08489\n",
      "[300]\tvalid_0's l1: 2.08102\n",
      "[350]\tvalid_0's l1: 2.07738\n",
      "[400]\tvalid_0's l1: 2.07209\n",
      "[450]\tvalid_0's l1: 2.06966\n",
      "[500]\tvalid_0's l1: 2.06726\n",
      "[550]\tvalid_0's l1: 2.06591\n",
      "[600]\tvalid_0's l1: 2.06266\n",
      "[650]\tvalid_0's l1: 2.06032\n",
      "[700]\tvalid_0's l1: 2.05895\n",
      "[750]\tvalid_0's l1: 2.05855\n",
      "[800]\tvalid_0's l1: 2.05772\n",
      "[850]\tvalid_0's l1: 2.05713\n",
      "[900]\tvalid_0's l1: 2.05702\n",
      "[950]\tvalid_0's l1: 2.05705\n",
      "[1000]\tvalid_0's l1: 2.05689\n",
      "[1050]\tvalid_0's l1: 2.05657\n",
      "[1100]\tvalid_0's l1: 2.05603\n",
      "[1150]\tvalid_0's l1: 2.05529\n",
      "[1200]\tvalid_0's l1: 2.05537\n",
      "[1250]\tvalid_0's l1: 2.05408\n",
      "[1300]\tvalid_0's l1: 2.05401\n",
      "[1350]\tvalid_0's l1: 2.0535\n",
      "[1400]\tvalid_0's l1: 2.05321\n",
      "[1450]\tvalid_0's l1: 2.05337\n",
      "[1500]\tvalid_0's l1: 2.05306\n",
      "[1550]\tvalid_0's l1: 2.0529\n",
      "[1600]\tvalid_0's l1: 2.05253\n",
      "[1650]\tvalid_0's l1: 2.05252\n",
      "[1700]\tvalid_0's l1: 2.05246\n",
      "[1750]\tvalid_0's l1: 2.05246\n",
      "[1800]\tvalid_0's l1: 2.0524\n",
      "[1850]\tvalid_0's l1: 2.05238\n",
      "[1900]\tvalid_0's l1: 2.05234\n",
      "[1950]\tvalid_0's l1: 2.05223\n",
      "[2000]\tvalid_0's l1: 2.05205\n",
      "[2050]\tvalid_0's l1: 2.05196\n",
      "[2100]\tvalid_0's l1: 2.05201\n",
      "[2150]\tvalid_0's l1: 2.0521\n",
      "[2200]\tvalid_0's l1: 2.05228\n",
      "Early stopping, best iteration is:\n",
      "[2017]\tvalid_0's l1: 2.05189\n"
     ]
    }
   ],
   "source": [
    "bst2 = lgb.train(params, tr2, valid_sets=[vl2], early_stopping_rounds=200, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1d272-23cc-4e64-82ca-9c4d86f74162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.914136\n",
      "[100]\tvalid_0's l1: 0.901449\n",
      "[150]\tvalid_0's l1: 0.899079\n"
     ]
    }
   ],
   "source": [
    "bst3 = lgb.train(params, tr3, valid_sets=[vl3], early_stopping_rounds=200, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5dc09-cf30-481a-abdf-9e024b5d6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst4 = lgb.train(params, tr4, valid_sets=[vl4], early_stopping_rounds=200, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b8073-511b-45a6-97fa-d48836315f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pred1 = bst1.predict(X_vl1)\n",
    "pred2 = bst2.predict(X_vl1)\n",
    "pred3 = bst3.predict(X_vl1)\n",
    "pred4 = bst4.predict(X_vl1)\n",
    "preds = np.vstack((pred1, pred2, pred3, pred4)).T\n",
    "print(mae(y_vl, preds))   # 1.367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c9813-4dcd-4e55-b644-651cfbbae99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.7930\n",
    "# 1.7708 - added lag of flags\n",
    "# 1.7368 - added categorical features from box score\n",
    "# 1.6982 - added batter scores\n",
    "# 1.6890       - added pitcher scores\n",
    "# 1.6892   - added remaining features ( :-( )\n",
    "# 1.6883     - added pitcher lags \n",
    "# 1.6810   - adde batter lags\n",
    "# 1.6777   - more pitcher lags\n",
    "# 1.5774 - added target mean (skip - 30 and last 365)\n",
    "# change hyperparams - colsamplebytree 0.7 --> 0.4; 1.6814 (reverting)\n",
    "# 1.534 - changed val to from 10 april - \n",
    "# 1.517 - added lag3\n",
    "# 1.5146 - changed hyperparams - colsample to 0.5\n",
    "# 1.509 - num_leaves 255\n",
    "# 1.5078  - min_leaf_samples 20\n",
    "# 1.4884 - added statusCode\n",
    "# 1.4891 - made it cat\n",
    "# 1.4795 - removed cat encoding\n",
    "# 1.4455 - fixed last n expanding mean and added last 10\n",
    "# 1.4396 - added last 10 stats\n",
    "# 1.4379 - last 5 innings sum of pitching scores\n",
    "# 1.4322 - last 5 mean scores\n",
    "# 1.4278 - expading mean batter scores\n",
    "# 1.4257 - expanding mean pitcher scores\n",
    "# 1.4070 - expanding sum - last 10 scores \n",
    "# 1.3687 -- changed validation to last 15 days\n",
    "# 1.3602 - changed target means from 10 days to 15 days \n",
    "# 1.3556 - changed from 15 to 30 days\n",
    "# 1.355 - changes days a bit\n",
    "# 1.3499 - changed lr to 0.05\n",
    "# 1.346 - changed hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a77301b1-a0e9-4290-8665-527dcc7b1bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f6a9cc48d90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst1.save_model(\"artifacts/bst1_train_v2.pkl\")\n",
    "bst2.save_model(\"artifacts/bst2_train_v2.pkl\")\n",
    "bst3.save_model(\"artifacts/bst3_train_v2.pkl\")\n",
    "bst4.save_model(\"artifacts/bst4_train_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d52475b7-1931-484c-a304-22ddc09b3f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seasonId</th>\n",
       "      <th>seasonStartDate</th>\n",
       "      <th>seasonEndDate</th>\n",
       "      <th>preSeasonStartDate</th>\n",
       "      <th>preSeasonEndDate</th>\n",
       "      <th>regularSeasonStartDate</th>\n",
       "      <th>regularSeasonEndDate</th>\n",
       "      <th>lastDate1stHalf</th>\n",
       "      <th>allStarDate</th>\n",
       "      <th>firstDate2ndHalf</th>\n",
       "      <th>postSeasonStartDate</th>\n",
       "      <th>postSeasonEndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-02-22</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>2018-10-28</td>\n",
       "      <td>2018-02-21</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-07-15</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2018-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2021-10-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seasonId seasonStartDate seasonEndDate preSeasonStartDate preSeasonEndDate  \\\n",
       "0      2017      2017-04-02    2017-11-01         2017-02-22       2017-04-01   \n",
       "1      2018      2018-03-29    2018-10-28         2018-02-21       2018-03-27   \n",
       "2      2019      2019-03-20    2019-10-30         2019-02-21       2019-03-26   \n",
       "3      2020      2020-07-23    2020-10-28         2020-02-21       2020-07-22   \n",
       "4      2021      2021-02-28    2021-10-31         2021-02-28       2021-03-30   \n",
       "\n",
       "  regularSeasonStartDate regularSeasonEndDate lastDate1stHalf allStarDate  \\\n",
       "0             2017-04-02           2017-10-01      2017-07-09  2017-07-11   \n",
       "1             2018-03-29           2018-10-01      2018-07-15  2018-07-17   \n",
       "2             2019-03-20           2019-09-29      2019-07-07  2019-07-09   \n",
       "3             2020-07-23           2020-09-27      2020-08-25         NaN   \n",
       "4             2021-04-01           2021-10-03      2021-07-11  2021-07-13   \n",
       "\n",
       "  firstDate2ndHalf postSeasonStartDate postSeasonEndDate  \n",
       "0       2017-07-14          2017-10-03        2017-11-01  \n",
       "1       2018-07-19          2018-10-02        2018-10-28  \n",
       "2       2019-07-11          2019-10-01        2019-10-30  \n",
       "3       2020-08-26          2020-09-29        2020-10-28  \n",
       "4       2021-07-15          2021-10-04        2021-10-31  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/seasons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce08fcf2-a5a8-43b4-afd8-51401ab475db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Running stats on rank per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce978ca2-3cc8-4aaa-b20e-7624bc5a6b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
